{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Simple Local AI Voice Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "1. Be able to control the voice assistant from voice\n",
    "2. BE able to talk to it as well as perform commands/actions \n",
    "3. Tasks\n",
    "   1. Create tasks in some task backlog db\n",
    "   2. Create, read, edit and delete files locally\n",
    "   3. Send emails\n",
    "   4. Fully local setup (audio transcription and the AI should be fully local)\n",
    "   5. Answer questions about personal notes and knowledge management stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "c:\\Users\\carli\\miniconda3\\envs\\cartalk\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:604: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n"
     ]
    }
   ],
   "source": [
    "# 1 - Voice Control \n",
    "# We'll need an audion transcription model to convert audio to text \n",
    "# We'll use whisper turbo 3\n",
    "# source: https://huggingface.co/openai/whisper-large-v3-turbo\n",
    "# pip install --upgrade pip\n",
    "# pip install --upgrade transformers datasets[audio] accelerate\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "result = pipe(\"audio-testfile.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering, which is the scattering of light by small particles in the atmosphere. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen and oxygen, as well as small particles like dust and water droplets. These particles scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is why the sky appears blue during the daytime, as the blue light is scattered in all directions and reaches our eyes from all parts of the sky.\n",
      "\n",
      "In addition to Rayleigh scattering, the sky can also appear blue due to a phenomenon called Mie scattering, which is the scattering of light by larger particles like dust and water droplets. This type of scattering occurs at shorter wavelengths than Rayleigh scattering and can make the sky appear more blue, especially in conditions where there are high levels of pollution or aerosols in the atmosphere.\n",
      "\n",
      "It's worth noting that the color of the sky can vary depending on the time of day, the amount of cloud cover, and the presence of aerosols and pollutants in the atmosphere. For example, during sunrise and sunset, the sky can take on hues of red, orange, and pink due to the scattering of light by particles in the atmosphere.\n"
     ]
    }
   ],
   "source": [
    "# 2 - Interaction using LLM\n",
    "# We'll use llama 3.2 with Ollama https://ollama.com/\n",
    "# pip install ollama\n",
    "# https://github.com/ollama/ollama-python\n",
    "\n",
    "import ollama\n",
    "response = ollama.chat(model='llama2:13b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThere is no definitive answer to what country has the best weather in the world, as weather conditions can vary greatly depending on the location and time of year. However, there are several countries that are known for their pleasant and consistent weather, such as:\\n\\n1. Hawaii, USA - Known for its tropical climate and warm temperatures year-round, with average temperatures ranging from 70°F to 85°F (21°C to 30°C).\\n2. Costa Rica - With a tropical climate and two distinct seasons (dry and rainy), Costa Rica offers mild weather conditions throughout the year, with average temperatures ranging from 70°F to 84°F (21°C to 30°C).\\n3. Australia - Australia has a diverse range of climates, but the southern states such as Tasmania and Victoria are known for their mild weather conditions, with average temperatures ranging from 50°F to 70°F (10°C to 21°C) during the summer months.\\n4. South Africa - The western coast of South Africa, particularly the region around Cape Town, is known for its mild and moderate climate, with average temperatures ranging from 50°F to 70°F (10°C to 21°C) throughout the year.\\n5. New Zealand - With a subtropical climate, New Zealand offers mild weather conditions, especially in the summer months (December to February), with average temperatures ranging from 60°F to 75°F (15°C to 24°C).\\n\\nIt's important to note that these are just a few examples of countries with pleasant weather conditions and there are many other destinations around the world that offer great weather as well. Additionally, it's always a good idea to check the local weather forecast before planning your trip to ensure the best conditions for your travel dates.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_response(prompt):\n",
    "    response = ollama.chat(model='llama2:13b', \n",
    "                           messages=[{'role': 'user', 'content': prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "get_response(\"What is the country known for having the best weather in the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n",
      "Audio saved as prompt.wav\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(filename=\"prompt.mp3\", duration=5, sample_rate=44100, channels=2, chunk=1024):\n",
    "    \"\"\"\n",
    "    Record audio from the microphone and save it to a file.\n",
    "    \n",
    "    :param filename: Name of the output file (default: \"prompt.mp3\")\n",
    "    :param duration: Duration of the recording in seconds (default: 5)\n",
    "    :param sample_rate: Sample rate of the recording (default: 44100 Hz)\n",
    "    :param channels: Number of audio channels (default: 2 for stereo)\n",
    "    :param chunk: Number of frames per buffer (default: 1024)\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=1,\n",
    "                    rate=sample_rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(sample_rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    wf = wave.open(filename.replace('.mp3', '.wav'), 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    print(f\"Audio saved as {filename.replace('.mp3', '.wav')}\")\n",
    "\n",
    "# Example usage:            \n",
    "record_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transcribe(audio_filepath):\n",
    "    result = pipe(audio_filepath)\n",
    "    return result.get(\"text\")\n",
    "\n",
    "transcribe(\"./prompt.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n",
      "Audio saved as prompt.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nI don\\'t understand what you mean by \",\". Could you explain?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_audio()\n",
    "prompt = transcribe(\"./prompt.wav\")\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stiching together models\n",
    "\n",
    "Taking the recorded transcripts and putting into llama3.2 for now\n",
    "Then have a Whisper model read out the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording finished.\n",
      "Audio saved as prompt.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nI don\\'t understand what you mean by \"<SYS>\" and \"</SYS>\". Could you explain?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-to-speech\", model=\"suno/bark\")\n",
    "\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"suno/bark\")\n",
    "model = AutoModel.from_pretrained(\"suno/bark\")\n",
    "\n",
    "inputs = processor(\n",
    "    text=[\"Hello, my name is Suno. And, uh — and I like pizza. [laughs] But I also have other interests such as playing tic tac toe.\"],\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "speech_values = model.generate(**inputs, do_sample=True)\n",
    "\n",
    "record_audio()\n",
    "prompt = transcribe(\"./prompt.wav\")\n",
    "get_response(prompt)\n",
    "# transcribe(\"./response.wav\")\n",
    "\n",
    "# def transcribe_and_respond(audio_input):\n",
    "#     if audio_input is None:\n",
    "#         return \"No audio input provided.\"\n",
    "\n",
    "#     # Transcribe the audio input\n",
    "#     transcription = transcribe(audio_input.name)\n",
    "#     if not transcription:\n",
    "#         return \"Transcription failed. Please try again.\"   \n",
    "#     # Get the response from the LLM\n",
    "#     response = get_response(transcription)\n",
    "#     if not response:\n",
    "#         return \"Failed to get a response from the LLM. Please try again.\"\n",
    "#     # Return the transcription and response\n",
    "#     return transcription, response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "   1. Create tasks in some task backlog db\n",
    "   2. Create, read, edit and delete files locally\n",
    "   3. Send emails\n",
    "   4. Fully local setup (audio transcription and the AI should be fully local)\n",
    "   5. Answer questions about personal notes and knowledge management stuff \n",
    "\n",
    "   6. GPS Directions\n",
    "   7. Local trivia\n",
    "   8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>status</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>completed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [task, status, creation_date, completed_date]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the task db first before writing the tools for the model\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Create an empty DataFrame for the tasks database\n",
    "tasks_df = pd.DataFrame(columns=['task', 'status', 'creation_date', 'completed_date'])\n",
    "\n",
    "tasks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool for adding a task\n",
    "def add_task(task_description):\n",
    "    \"\"\"\n",
    "    Add a task to the tasks database.\n",
    "    \"\"\"\n",
    "    new_task = pd.DataFrame({\n",
    "        'task': [task_description],\n",
    "        'status': ['Not Started'],\n",
    "        'creation_date': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "        'completed_date': [None]\n",
    "    })\n",
    "    global tasks_df\n",
    "    tasks_df = pd.concat([tasks_df, new_task], ignore_index=True)\n",
    "    \n",
    "    return tasks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling\n",
    "\n",
    "Tool calling is about giving LLMs the ability to perform actions.\n",
    "\n",
    "```\n",
    "{\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'create_file',\n",
    "        'description': 'Create a new file with given content',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'filename': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The name of the file to create',\n",
    "                },\n",
    "                'content': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The content to write to the file',\n",
    "                },\n",
    "            },\n",
    "            'required': ['filename', 'content'],\n",
    "        },\n",
    "    },\n",
    "},\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_add_tasks_to_db = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'add_task',\n",
    "        'description': 'Add a task to the tasks database',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'task_description': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The description of the task to add',\n",
    "                },\n",
    "            },\n",
    "            'required': ['task_description'],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tasks in a backlog task db\n",
    "def get_response_with_tools(prompt):\n",
    "    response = ollama.chat(model='llama3.2', \n",
    "                           messages=[{'role': 'user', 'content': prompt}],\n",
    "                           tools=[tool_add_tasks_to_db])\n",
    "    # Process tool calls if present\n",
    "    if 'tool_calls' in response['message']:\n",
    "        for tool_call in response['message']['tool_calls']:\n",
    "            if tool_call['function']['name'] == 'add_task':\n",
    "                task_description = tool_call['function']['arguments']['task_description']\n",
    "                add_task(task_description)\n",
    "                print(f\"Task added: {task_description}\")\n",
    "    else:\n",
    "        return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task added: Create a local voice AI assistant\n"
     ]
    }
   ],
   "source": [
    "get_response_with_tools(\"Create a task to create a local voice AI assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>status</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>completed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create a local voice AI assistant</td>\n",
       "      <td>Not Started</td>\n",
       "      <td>2025-07-16 14:16:46</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                task       status        creation_date  \\\n",
       "0  Create a local voice AI assistant  Not Started  2025-07-16 14:16:46   \n",
       "\n",
       "  completed_date  \n",
       "0           None  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_create_file = {\n",
    "            'type': 'function',\n",
    "            'function': {\n",
    "                'name': 'create_file',\n",
    "                'description': 'Create a new file with given content',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'filename': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The name of the file to create',\n",
    "                        },\n",
    "                        'content': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The content to write to the file',\n",
    "                        },\n",
    "                    },\n",
    "                    'required': ['filename', 'content'],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "tool_read_file = {\n",
    "            'type': 'function',\n",
    "            'function': {\n",
    "                'name': 'read_file',\n",
    "                'description': 'Read the content of a file',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'filename': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The name of the file to read',\n",
    "                        },\n",
    "                    },\n",
    "                    'required': ['filename'],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "tool_delete_file = {\n",
    "            'type': 'function',\n",
    "            'function': {\n",
    "                'name': 'delete_file',\n",
    "                'description': 'Delete a file',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'filename': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The name of the file to delete',\n",
    "                        },\n",
    "                    },\n",
    "                    'required': ['filename'],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "tool_edit_file = {\n",
    "            'type': 'function', \n",
    "            'function': {\n",
    "                'name': 'edit_file',\n",
    "                'description': 'Edit the content of a file',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'filename': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The name of the file to edit',\n",
    "                        },\n",
    "                        'content': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The content to write to the file',\n",
    "                        },\n",
    "                    },\n",
    "                    'required': ['filename', 'content'],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "tools = [tool_create_file, tool_read_file, tool_delete_file, tool_add_tasks_to_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Writing functions to create, read, edit and delete files\n",
    "\n",
    "def create_file(filename, content):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)\n",
    "    return f\"File {filename} created successfully\"\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "def edit_file(filename, content):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)\n",
    "    return f\"File {filename} edited successfully\"\n",
    "\n",
    "def delete_file(filename):\n",
    "    os.remove(filename)\n",
    "    return f\"File {filename} deleted successfully\"\n",
    "\n",
    "# Creating tasks in a backlog task db\n",
    "def get_response_with_tools(prompt):\n",
    "    response = ollama.chat(model='llama3.2', \n",
    "                           messages=[{'role': 'user', 'content': prompt}],\n",
    "                           tools=tools)\n",
    "    # Process tool calls if present\n",
    "    if 'tool_calls' in response['message']:\n",
    "        for tool_call in response['message']['tool_calls']:\n",
    "            if tool_call['function']['name'] == 'add_task':\n",
    "                task_description = tool_call['function']['arguments']['task_description']\n",
    "                add_task(task_description)\n",
    "                print(f\"Task added: {task_description}\")\n",
    "            elif tool_call['function']['name'] == 'create_file':\n",
    "                print(\"Creating file...\")\n",
    "                filename = tool_call['function']['arguments']['filename']\n",
    "                content = tool_call['function']['arguments']['content']\n",
    "                create_file(filename, content)\n",
    "                print(f\"File created: {filename}\")\n",
    "            elif tool_call['function']['name'] == 'read_file':\n",
    "                print(\"Reading file...\")\n",
    "                filename = tool_call['function']['arguments']['filename']\n",
    "                content = read_file(filename)\n",
    "                print(f\"File content: {content}\")\n",
    "            elif tool_call['function']['name'] == 'delete_file':\n",
    "                print(\"Deleting file...\")\n",
    "                filename = tool_call['function']['arguments']['filename']\n",
    "                delete_file(filename)\n",
    "                print(f\"File deleted: {filename}\")\n",
    "    else:\n",
    "        return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file...\n",
      "File created: test.txt\n"
     ]
    }
   ],
   "source": [
    "get_response_with_tools(\"Create a file called 'test.txt' with the content 'Hello, world!'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>status</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>completed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create a local voice AI assistant</td>\n",
       "      <td>Not Started</td>\n",
       "      <td>2025-07-16 14:16:46</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                task       status        creation_date  \\\n",
       "0  Create a local voice AI assistant  Not Started  2025-07-16 14:16:46   \n",
       "\n",
       "  completed_date  \n",
       "0           None  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n",
      "Audio saved as prompt.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carli\\miniconda3\\envs\\ace\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:604: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file...\n",
      "File created: experience.txt\n"
     ]
    }
   ],
   "source": [
    "record_audio(duration=5)\n",
    "prompt = transcribe(\"./prompt.wav\")\n",
    "get_response_with_tools(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks saved to tasks.csv\n"
     ]
    }
   ],
   "source": [
    "# Save tasks_df to CSV file\n",
    "tasks_df.to_csv('tasks.csv', index=False)\n",
    "print(\"Tasks saved to tasks.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cartalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
